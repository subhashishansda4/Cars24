{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    website = 'https://www.cars24.com/buy-used-car?f=make%3A%3D%3Amahindra&sort=bestmatch&serveWarrantyCount=true&gaId=1534543658.1720027803&listingSource=TabFilter&storeCityId=2378'\n",
        "    response=requests.get(website)\n",
        "    response.status_code\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    links = soup.find_all(\"a\", attrs={'class': 'IIJDn'})\n",
        "    link_list = []\n",
        "    for link in links:\n",
        "        link_list.append(link.get('href'))\n",
        "    d = {\"Car_Model\": [], \"Location\": [], \"EMI\": [], \"Price\": [], \"Transmission\": [], \"Fuel_Type\": []}\n",
        "    for link in link_list:\n",
        "        new_webpage = requests.get(link)\n",
        "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
        "        # Use .get() to avoid errors if elements are not found and provide a default empty string\n",
        "        d[\"Car_Model\"].append(new_soup.find('h1', {'class': '_2Ximl'}).text.strip() if new_soup.find('h1', {'class': '_2Ximl'}) else '')\n",
        "        d[\"Location\"].append(new_soup.find('li', {'class': '_1Rvdw'}).text.rstrip(\"\\n\").strip() if new_soup.find('li', {'class': '_1Rvdw'}) else '')\n",
        "        d[\"EMI\"].append(new_soup.find(\"strong\", attrs={\"class\": '_3i9_p _3d4o3'}).text.strip() if new_soup.find(\"strong\", attrs={\"class\": '_3i9_p'}) else '')\n",
        "        d[\"Price\"].append(new_soup.find(\"div\", attrs={\"class\":'d-flex align-items-center'}).find(\"strong\").text if new_soup.find(\"div\", attrs={\"class\": 'd-flex align-items-center'}).find(\"strong\") else '')\n",
        "        d[\"Transmission\"].append(new_soup.find(\"ul\", attrs={\"class\":'_2JSmz'}).find_all(\"li\")[3].text if new_soup.find(\"ul\", attrs={\"class\": '_2JSmz'}).find_all(\"li\")[3] else '')\n",
        "        d[\"Fuel_Type\"].append(new_soup.find(\"ul\", attrs={\"class\":'_2JSmz'}).find_all(\"li\")[2].text if new_soup.find(\"ul\", attrs={\"class\": '_2JSmz'}).find_all(\"li\")[2] else '')\n",
        "\n",
        "    # Create the DataFrame after the loop\n",
        "    cars_df = pd.DataFrame(d)\n",
        "    # Handle missing values and save to CSV\n",
        "    cars_df.replace('', np.nan, inplace=True)  # Replace empty strings with NaN\n",
        "    cars_df.dropna(subset=['Car_Model'], inplace=True)  # Drop rows with missing 'Car_Model' values\n",
        "    cars_df.to_csv(\"cars.csv\", header=True, index=False)"
      ],
      "metadata": {
        "id": "z0Bu2Trzk-aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGlYWKwVI9D_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}